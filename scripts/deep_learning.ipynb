{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b11433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athithiyan/anaconda3/envs/lila/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/athithiyan/anaconda3/envs/lila/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /Users/athithiyan/anaconda3/envs/lila/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/athithiyan/anaconda3/envs/lila/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/athithiyan/anaconda3/envs/lila/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/athithiyan/anaconda3/envs/lila/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/athithiyan/anaconda3/envs/lila/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "--- STEP 1: TRAINING ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 179\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# ==================================================\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# CLI SAFE\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# ==================================================\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 153\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(patch_img, patch_msk, sentinel_root, tiles, year, out_dir, model_path, epochs, batch_size, threshold)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEVICE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- STEP 1: TRAINING ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_msk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- STEP 2: PREDICTION ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m out_dir \u001b[38;5;241m=\u001b[39m Path(out_dir)\n",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(patch_img, patch_msk, model_path, epochs, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ds) \u001b[38;5;241m-\u001b[39m train_size\n\u001b[1;32m     46\u001b[0m train_ds, val_ds \u001b[38;5;241m=\u001b[39m random_split(ds, [train_size, val_size])\n\u001b[0;32m---> 48\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m val_dl   \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnet(\n\u001b[1;32m     52\u001b[0m     encoder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet34\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     encoder_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,   \u001b[38;5;66;03m# B02,B03,B04,B08,B11\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     56\u001b[0m )\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m~/anaconda3/envs/lila/lib/python3.10/site-packages/torch/utils/data/dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lila/lib/python3.10/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==================================================\n",
    "# DEVICE\n",
    "# ==================================================\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "# ==================================================\n",
    "# DATASET\n",
    "# ==================================================\n",
    "class BuiltupDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, mask_dir):\n",
    "        self.imgs = sorted(Path(img_dir).glob(\"*.npy\"))\n",
    "        self.masks = sorted(Path(mask_dir).glob(\"*.npy\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = np.load(self.imgs[i]).astype(\"float32\") / 10000.0\n",
    "        y = np.load(self.masks[i]).astype(\"float32\")\n",
    "        return torch.tensor(x), torch.tensor(y).unsqueeze(0)\n",
    "\n",
    "# ==================================================\n",
    "# TRAIN\n",
    "# ==================================================\n",
    "def train_model(patch_img, patch_msk, model_path, epochs=25, batch_size=4):\n",
    "\n",
    "    ds = BuiltupDataset(patch_img, patch_msk)\n",
    "\n",
    "    train_size = int(0.8 * len(ds))\n",
    "    val_size = len(ds) - train_size\n",
    "    train_ds, val_ds = random_split(ds, [train_size, val_size])\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_dl   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=5,   # B02,B03,B04,B08,B11\n",
    "        classes=1\n",
    "    ).to(DEVICE)\n",
    "    dice_loss = smp.losses.DiceLoss(mode=\"binary\")\n",
    "    bce_loss  = torch.nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t_loss = 0\n",
    "\n",
    "        for x,y in tqdm(train_dl, desc=f\"Epoch {ep+1}/{epochs}\"):\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            p = model(x)\n",
    "            loss = dice_loss(p, y) + bce_loss(p, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            t_loss += loss.item()\n",
    "\n",
    "        print(\"Train loss:\", t_loss/len(train_dl))\n",
    "\n",
    "        model.eval()\n",
    "        v_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_dl:\n",
    "                x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "                p = model(x)\n",
    "                v_loss += (dice_loss(p, y) + bce_loss(p, y)).item()   \n",
    "\n",
    "        print(\"Val loss:\", v_loss/len(val_dl))\n",
    "\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==================================================\n",
    "# PREDICT TILE\n",
    "# ==================================================\n",
    "def predict_tile(model, stack_path, out_prob, out_mask, patch=256, thresh=0.6):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with rasterio.open(stack_path) as src:\n",
    "        profile = src.profile\n",
    "        H, W = src.height, src.width\n",
    "\n",
    "        profile.update(dtype=\"float32\", count=1, compress=\"DEFLATE\")\n",
    "\n",
    "        with rasterio.open(out_prob, \"w\", **profile) as dp, \\\n",
    "             rasterio.open(out_mask, \"w\", **{**profile, \"dtype\": \"uint8\"}) as dm:\n",
    "\n",
    "            for row in range(0, H, patch):\n",
    "                for col in range(0, W, patch):\n",
    "\n",
    "                    h = min(patch, H - row)\n",
    "                    w = min(patch, W - col)\n",
    "\n",
    "                    win = Window(col, row, w, h)\n",
    "                    img = src.read(window=win).astype(\"float32\") / 10000.0\n",
    "\n",
    "                    if img.shape[1] < patch or img.shape[2] < patch:\n",
    "                        pad = np.zeros((img.shape[0], patch, patch), dtype=\"float32\")\n",
    "                        pad[:, :h, :w] = img\n",
    "                        img = pad\n",
    "\n",
    "                    x = torch.tensor(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        p = torch.sigmoid(model(x))[0,0].cpu().numpy()\n",
    "\n",
    "                    p = p[:h, :w]\n",
    "                    m = (p >= thresh).astype(\"uint8\")\n",
    "\n",
    "                    dp.write(p, 1, window=win)\n",
    "                    dm.write(m, 1, window=win)\n",
    "\n",
    "# ==================================================\n",
    "# PUBLIC RUN FUNCTION (LIKE YOUR STYLE)\n",
    "# ==================================================\n",
    "def run(\n",
    "    patch_img=\"data/patches/images\",\n",
    "    patch_msk=\"data/patches/masks\",\n",
    "    sentinel_root=\"data/sentinel\",\n",
    "    tiles=(\"T44PMV\",),\n",
    "    year=2025,\n",
    "    out_dir=\"output/predictions\",\n",
    "    model_path=\"models/builtup_unet_m2.pth\",\n",
    "    epochs=25,\n",
    "    batch_size=4,\n",
    "    threshold=0.6,\n",
    "):\n",
    "\n",
    "    print(\"Using device:\", DEVICE)\n",
    "\n",
    "    print(\"\\n--- STEP 1: TRAINING ---\")\n",
    "    model = train_model(patch_img, patch_msk, model_path, epochs, batch_size)\n",
    "\n",
    "    print(\"\\n--- STEP 2: PREDICTION ---\")\n",
    "    out_dir = Path(out_dir)\n",
    "\n",
    "    for tile in tiles:\n",
    "        stack = Path(sentinel_root)/tile/str(year)/\"dl_stack\"/\"S2_DL_STACK.tif\"\n",
    "\n",
    "        out_tile = out_dir/tile/str(year)\n",
    "        out_tile.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        predict_tile(\n",
    "            model,\n",
    "            stack_path=stack,\n",
    "            out_prob=out_tile/\"BUILTUP_PROB_DL.tif\",\n",
    "            out_mask=out_tile/\"BUILTUP_MASK_DL.tif\",\n",
    "            patch=256,\n",
    "            thresh=threshold\n",
    "        )\n",
    "\n",
    "    print(\"\\nðŸŽ‰ TRAINING + PREDICTION COMPLETED\")\n",
    "\n",
    "# ==================================================\n",
    "# CLI SAFE\n",
    "# ==================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83980f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
